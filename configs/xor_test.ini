[model]
architecture = 2,8,1
hidden_activation = relu
output_activation = sigmoid

[training]
epochs = 200
batch_size = 4
learning_rate = 0.5
optimizer = sgd
lr_decay = 0.999
lr_decay_steps = 100

[data]
train_data = csv/xor_train.csv
train_labels = csv/xor_labels.csv
val_data = csv/xor_train.csv
val_labels = csv/xor_labels.csv

[loss]
loss_function = bce

[logging]
print_every = 100
validate_every = 0

[options]
shuffle = true
random_seed = 42
